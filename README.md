# [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge)

### In this Kaggle challenge, BERT is used to obtain contextualized word embeddings, then embeddings from the last 4 layers are averaged. After that linear layers give the value of each target. BERT with linear layers train for several epochs, then linear layers train additional (it is need much more epochs for them).
